# 数据偏斜

数据的类别不平衡（class imbalance），也叫数据偏斜（class skew）。以常见的二分类问题为例，我们希望预测病人是否得了某种罕见疾病。但在历史数据中，阳性的比例可能很低（如百分之0.1）。在这种情况下，学习出好的分类器是很难的，分类器的精度可能很高，但我们更关心召回率。

## 简单通用的算法

- 对数据进行采用的过程中通过相似性同时生成并插样“少数类别数据”，叫做SMOTE算法
- 对数据先进行聚类，再将大的簇进行随机欠采样或者小的簇进行数据生成
- 把监督学习变为无监督学习，舍弃掉标签把问题转化为一个无监督问题，如异常检测
- 先对多数类别进行随机的欠采样，并结合boosting算法进行集成学习

``总结起来就是，对样本数量多的类别进行欠采样，或者对样本数量少的类别进行过采样，使各类别数据数量相当。但无论是过采样还是欠采样都改变了数据的分布，数据不再是真实数据的无偏表述。过采样无中生有或者重复使用数据，会导致过拟合产生，而欠采样浪费了数据。``